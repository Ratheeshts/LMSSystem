{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'owlready2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9eee63de1d99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mowlready2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'owlready2'"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "from owlready2 import *\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\"\"\"python functions to manage E-Learner ontology \n",
    "This class will contains the methods to build e-Learner ontology.\n",
    " \"\"\"\n",
    "onto = get_ontology(\"http://elearning1.org/onto.owl\")\n",
    "       # onto = get_ontology(file_name).load()        \n",
    "#loadOnto('onto.owl')      \n",
    "#constructor -passing file name of the ontology if owl file is already existed\n",
    "#or create new ontoloby\n",
    "def loadOnto(file_name='onto.owl'):\n",
    "    ontology_file=file_name\n",
    "    if path.exists(file_name):\n",
    "        print('Ontology file found')\n",
    "        onto = get_ontology(file_name).load()        \n",
    "    else:\n",
    "        print('Ontology file not found '+file_name)\n",
    "        onto = get_ontology(\"http://elearning1.org/onto.owl\")\n",
    "    return\n",
    "\n",
    "#functions to create Ontology class\n",
    "with onto:\n",
    " class Learner(Thing):\n",
    "       pass\n",
    " class Age(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[str]\n",
    " class Name(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[str]\n",
    " class Gender(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[str]\n",
    " class Qualification(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[str] \n",
    " class Branch(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[str]\n",
    " class Background_Knowledge(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[str]\n",
    " class Active_Reflective(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[int] \n",
    " class AR_Value(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[int] \n",
    " class Sensitive_Intutive(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[int]\n",
    " class S_I_Value(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[int]\n",
    " class Visual_Verbal(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[int]\n",
    " class V_V_Value(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[int]\n",
    " class Global_Sequential(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[int]\n",
    " class G_S_Value(DataProperty):\n",
    "        domain = [Learner]\n",
    "        range=[int]\n",
    "   \n",
    "#check wether value is dominant\n",
    "def isDominant(score):\n",
    "    score_min=score-50\n",
    "    if score_min>0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def activeOrReflective(score):\n",
    "    if isDominant(score):\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "    \n",
    "def sensitiveOrIntutive(score):\n",
    "    if isDominant(score):\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "def visualOrVerbal(score):\n",
    "    if isDominant(score):\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "def Global_Sequential(score):\n",
    "    if isDominant(score):\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('LearnerOntology_InitialDataLoad.xlsx')\n",
    "df1 = pd.read_excel(xls, 'learner_static')\n",
    "df2 = pd.read_excel(xls, 'learning_style')\n",
    "learner_data=pd.merge(df1,df2,how='inner',on='SID')\n",
    "learner_data['Active_Reflective']=''\n",
    "learner_data['Sensitive_Intutive']=''\n",
    "learner_data['Visual_Verbal']=''\n",
    "learner_data['Global_Sequential']=''\n",
    "columns=list(learner_data.columns) \n",
    "learner_data['Active_Reflective'] = learner_data.apply(lambda x: activeOrReflective(x.Active), axis=1)\n",
    "learner_data['Sensitive_Intutive'] =learner_data.apply(lambda x: sensitiveOrIntutive(x.Sensitive), axis=1)\n",
    "learner_data['Visual_Verbal'] =learner_data.apply(lambda x: visualOrVerbal(x.Visual), axis=1)\n",
    "learner_data['Global_Sequential'] =learner_data.apply(lambda x: Global_Sequential(x.Global), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_data\n",
    "\n",
    "def findBK(bk):\n",
    "    return Background.index(bk)\n",
    "def findQual(qual):\n",
    "    return Qualification.index(qual)\n",
    "Background=list(learner_data['Background Knowledge'].unique())\n",
    "Qualification=list(learner_data['Qualification'].unique())\n",
    "learner_data['Background Knowledge'] =learner_data.apply(lambda x: findBK(x['Background Knowledge']), axis=1)\n",
    "learner_data['Qualification'] =learner_data.apply(lambda x: findQual(x['Qualification']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #create student individual \n",
    "def createStudentIndividual(stud):\n",
    "    \"\"\"This method will create Student Object\"\"\"\n",
    "    print(stud)\n",
    "    studobj=onto.Learner(stud[1]) \n",
    "    studobj.Name.append(stud[1])\n",
    "    studobj.Age.append(stud[2])\n",
    "    studobj.Gender.append(stud[3])\n",
    "    studobj.Qualification.append(stud[4])\n",
    "    studobj.Branch.append(stud[5])\n",
    "    studobj.Background_Knowledge.append(stud[6])\n",
    "    studobj.Active_Reflective.append(stud[11])\n",
    "    studobj.AR_Value.append(stud[7])\n",
    "    studobj.Sensitive_Intutive.append(stud[12])\n",
    "    studobj.S_I_Value.append(stud[8])\n",
    "    studobj.Visual_Verbal.append(stud[13])\n",
    "    studobj.V_V_Value.append(stud[9])\n",
    "    studobj.Global_Sequential.append(stud[14])\n",
    "    studobj.G_S_Value.append(stud[10])\n",
    "    return\n",
    "     #convert csv input to learmer ontology\n",
    "def csv2StudOnto(df):\n",
    "    \"\"\" read csv_file using pandas,csv_file=file name\"\"\"\n",
    "    for row in df.itertuples():#iterate through rows\n",
    "        createStudentIndividual(list(row[1:]))#get each rows, skip first value\n",
    "    #save ontology to a File\n",
    "def saveOntology(file_format=\"rdfxml\"):\n",
    "    onto.save(file = 'ontology2.owl', format = file_format)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 'L1', 18, 'M', 0, 'Mathematics with Computer', 0, 70, 40, 60, 50, '1', '0', '1', '0']\n",
      "[2, 'L2', 19, 'M', 0, 'Science', 0, 60, 70, 20, 40, '1', '1', '0', '0']\n",
      "[3, 'L3', 17, 'M', 0, 'Mathematics with Computer', 1, 47, 62, 49, 28, '0', '1', '0', '0']\n",
      "[4, 'L4', 19, 'M', 0, 'Science', 2, 30, 65, 81, 36, '0', '1', '1', '0']\n",
      "[5, 'L5', 18, 'M', 0, 'Mathematics with Computer', 0, 78, 34, 23, 87, '1', '0', '0', '1']\n",
      "[6, 'L6', 18, 'M', 0, 'Mathematics with Computer', 1, 34, 58, 44, 74, '0', '1', '0', '1']\n",
      "[7, 'L7', 17, 'M', 0, 'Science', 2, 87, 33, 55, 65, '1', '0', '1', '1']\n",
      "[8, 'L8', 19, 'M', 0, 'Mathematics with Computer', 0, 84, 87, 76, 69, '1', '1', '1', '1']\n",
      "[9, 'L9', 18, 'M', 0, 'Mathematics with Computer', 1, 23, 84, 24, 34, '0', '1', '0', '0']\n",
      "[10, 'L10', 18, 'M', 0, 'Science', 0, 65, 76, 58, 45, '1', '1', '1', '0']\n",
      "[11, 'L11', 17, 'M', 0, 'Mathematics with Computer', 2, 65, 86, 64, 47, '1', '1', '1', '0']\n",
      "[12, 'L12', 18, 'M', 0, 'Science', 0, 75, 34, 22, 62, '1', '0', '0', '1']\n",
      "[13, 'L13', 18, 'M', 0, 'Mathematics with Computer', 0, 56, 54, 81, 57, '1', '1', '1', '1']\n",
      "[14, 'L14', 19, 'M', 0, 'Mathematics with Computer', 0, 54, 45, 54, 24, '1', '0', '1', '0']\n",
      "[15, 'L15', 17, 'M', 0, 'Science', 0, 55, 54, 87, 64, '1', '1', '1', '1']\n",
      "[16, 'L16', 19, 'M', 0, 'Mathematics with Computer', 1, 51, 82, 45, 54, '1', '1', '0', '1']\n",
      "[17, 'L17', 18, 'F', 0, 'Science', 0, 59, 25, 79, 25, '1', '0', '1', '0']\n",
      "[18, 'L18', 18, 'F', 0, 'Mathematics with Computer', 2, 85, 46, 84, 26, '1', '0', '1', '0']\n",
      "[19, 'L19', 17, 'F', 0, 'Mathematics with Computer', 1, 63, 16, 57, 65, '1', '0', '1', '1']\n",
      "[20, 'L20', 19, 'F', 0, 'Science', 0, 19, 68, 46, 83, '0', '1', '0', '1']\n",
      "[21, 'L21', 18, 'F', 0, 'Mathematics with Computer', 1, 84, 87, 76, 69, '1', '1', '1', '1']\n",
      "[22, 'L22', 18, 'F', 0, 'Science', 0, 23, 84, 24, 34, '0', '1', '0', '0']\n",
      "[23, 'L23', 17, 'F', 0, 'Science', 0, 65, 76, 58, 45, '1', '1', '1', '0']\n",
      "[24, 'L24', 19, 'F', 0, 'Mathematics with Computer', 0, 65, 86, 64, 47, '1', '1', '1', '0']\n",
      "[25, 'L25', 18, 'F', 0, 'Science', 0, 75, 34, 22, 62, '1', '0', '0', '1']\n",
      "[26, 'L26', 17, 'F', 0, 'Mathematics with Computer', 2, 56, 54, 81, 57, '1', '1', '1', '1']\n",
      "[27, 'L27', 18, 'F', 0, 'Mathematics with Computer', 0, 54, 45, 54, 24, '1', '0', '1', '0']\n",
      "[28, 'L28', 18, 'F', 0, 'Science', 2, 55, 54, 87, 64, '1', '1', '1', '1']\n",
      "[29, 'L29', 19, 'F', 0, 'Mathematics with Computer', 2, 51, 82, 45, 54, '1', '1', '0', '1']\n",
      "[30, 'L30', 17, 'F', 0, 'Science', 0, 65, 36, 71, 88, '1', '0', '1', '1']\n",
      "[31, 'L31', 22, 'M', 1, 'BTech Computer Science', 0, 70, 45, 67, 58, '1', '0', '1', '1']\n",
      "[32, 'L32', 24, 'M', 1, 'BTech Information Technology', 0, 67, 70, 20, 40, '1', '1', '0', '0']\n",
      "[33, 'L33', 21, 'M', 1, 'BSc Computer Science', 1, 47, 62, 49, 28, '0', '1', '0', '0']\n",
      "[34, 'L34', 25, 'M', 1, 'BSc Computer Science', 2, 30, 46, 81, 36, '0', '0', '1', '0']\n",
      "[35, 'L35', 23, 'M', 1, 'BTech Information Technology', 0, 78, 34, 17, 87, '1', '0', '0', '1']\n",
      "[36, 'L36', 22, 'M', 1, 'BTech Computer Science', 1, 34, 34, 76, 74, '0', '0', '1', '1']\n",
      "[37, 'L37', 21, 'M', 1, 'BTech Information Technology', 2, 87, 44, 55, 65, '1', '0', '1', '1']\n",
      "[38, 'L38', 24, 'M', 1, 'BTech Computer Science', 0, 84, 87, 54, 69, '1', '1', '1', '1']\n",
      "[39, 'L39', 22, 'M', 1, 'BSc Computer Science', 1, 23, 84, 24, 34, '0', '1', '0', '0']\n",
      "[40, 'L40', 22, 'M', 1, 'BTech Computer Science', 0, 65, 67, 58, 45, '1', '1', '1', '0']\n",
      "[42, 'L42', 23, 'M', 1, 'BSc Computer Science', 0, 75, 34, 22, 62, '1', '0', '0', '1']\n",
      "[44, 'L44', 21, 'M', 1, 'BTech Information Technology', 0, 54, 57, 54, 24, '1', '1', '1', '0']\n",
      "[45, 'L45', 24, 'M', 1, 'BTech Computer Science', 0, 55, 54, 87, 64, '1', '1', '1', '1']\n",
      "[46, 'L46', 22, 'M', 1, 'BTech Information Technology', 1, 68, 82, 45, 54, '1', '1', '0', '1']\n",
      "[46, 'L46', 22, 'M', 1, 'BTech Information Technology', 1, 65, 86, 64, 47, '1', '1', '1', '0']\n",
      "[47, 'L47', 23, 'M', 1, 'BTech Computer Science', 0, 59, 32, 79, 25, '1', '0', '1', '0']\n",
      "[48, 'L48', 21, 'M', 1, 'BSc Computer Science', 2, 85, 46, 84, 26, '1', '0', '1', '0']\n",
      "[49, 'L49', 23, 'M', 1, 'BTech Information Technology', 1, 76, 86, 43, 29, '1', '1', '0', '0']\n",
      "[49, 'L49', 23, 'M', 1, 'BTech Information Technology', 1, 63, 16, 57, 65, '1', '0', '1', '1']\n",
      "[50, 'L50', 22, 'M', 1, 'BTech Computer Science', 0, 19, 68, 46, 83, '0', '1', '0', '1']\n",
      "[51, 'L51', 23, 'M', 1, 'BSc Computer Science', 1, 84, 87, 76, 69, '1', '1', '1', '1']\n",
      "[52, 'L52', 23, 'M', 1, 'BTech Computer Science', 0, 23, 84, 19, 34, '0', '1', '0', '0']\n",
      "[53, 'L53', 22, 'M', 1, 'BTech Information Technology', 0, 65, 76, 58, 45, '1', '1', '1', '0']\n",
      "[55, 'L55', 24, 'F', 1, 'BSc Computer Science', 0, 76, 37, 69, 49, '1', '0', '1', '0']\n",
      "[55, 'L55', 24, 'F', 1, 'BSc Computer Science', 0, 75, 34, 22, 62, '1', '0', '0', '1']\n",
      "[56, 'L56', 23, 'F', 1, 'BTech Information Technology', 2, 56, 80, 81, 57, '1', '1', '1', '1']\n",
      "[57, 'L57', 21, 'F', 1, 'BTech Computer Science', 0, 54, 45, 54, 24, '1', '0', '1', '0']\n",
      "[58, 'L58', 22, 'F', 1, 'BTech Information Technology', 2, 75, 54, 87, 64, '1', '1', '1', '1']\n",
      "[59, 'L59', 23, 'F', 1, 'BTech Computer Science', 2, 51, 82, 45, 54, '1', '1', '0', '1']\n",
      "[60, 'L60', 22, 'F', 1, 'BSc Computer Science', 0, 65, 41, 71, 88, '1', '0', '1', '1']\n",
      "[61, 'L61', 21, 'F', 1, 'BTech Computer Science', 2, 75, 34, 22, 62, '1', '0', '0', '1']\n",
      "[62, 'L62', 23, 'F', 1, 'BTech Information Technology', 1, 56, 54, 81, 57, '1', '1', '1', '1']\n",
      "[63, 'L63', 22, 'F', 1, 'BSc Computer Science', 0, 54, 45, 54, 24, '1', '0', '1', '0']\n",
      "[64, 'L64', 22, 'F', 1, 'BSc Computer Science', 1, 55, 54, 87, 64, '1', '1', '1', '1']\n",
      "[65, 'L65', 23, 'F', 1, 'BTech Information Technology', 0, 51, 82, 45, 54, '1', '1', '0', '1']\n",
      "[66, 'L66', 24, 'F', 1, 'BTech Computer Science', 0, 59, 25, 79, 25, '1', '0', '1', '0']\n",
      "[67, 'L67', 24, 'F', 1, 'BTech Information Technology', 0, 85, 46, 84, 26, '1', '0', '1', '0']\n",
      "[68, 'L68', 22, 'F', 1, 'BTech Computer Science', 0, 63, 16, 57, 65, '1', '0', '1', '1']\n",
      "[69, 'L69', 23, 'F', 1, 'BSc Computer Science', 2, 19, 68, 46, 83, '0', '1', '0', '1']\n",
      "[70, 'L70', 22, 'F', 1, 'BTech Computer Science', 0, 84, 87, 76, 69, '1', '1', '1', '1']\n",
      "[71, 'L71', 23, 'F', 1, 'BTech Information Technology', 2, 23, 84, 24, 34, '0', '1', '0', '0']\n",
      "[72, 'L72', 23, 'F', 1, 'BSc Computer Science', 2, 65, 76, 58, 45, '1', '1', '1', '0']\n",
      "[73, 'L73', 22, 'F', 1, 'BSc Computer Science', 0, 65, 86, 64, 47, '1', '1', '1', '0']\n",
      "[74, 'L74', 21, 'F', 1, 'BTech Information Technology', 0, 75, 34, 22, 62, '1', '0', '0', '1']\n",
      "[75, 'L75', 24, 'F', 1, 'BTech Computer Science', 0, 56, 54, 81, 57, '1', '1', '1', '1']\n",
      "[76, 'L76', 25, 'M', 2, 'Master of Computer Applications', 1, 54, 45, 54, 24, '1', '0', '1', '0']\n",
      "[77, 'L77', 24, 'M', 2, 'MTech Computer Science', 2, 55, 54, 87, 64, '1', '1', '1', '1']\n",
      "[78, 'L78', 26, 'M', 2, 'MSc Computer Science', 0, 51, 82, 45, 54, '1', '1', '0', '1']\n",
      "[79, 'L79', 24, 'M', 2, 'MSc Computer Science', 2, 65, 36, 71, 88, '1', '0', '1', '1']\n",
      "[80, 'L80', 28, 'M', 2, 'MTech Computer Science', 1, 70, 45, 67, 58, '1', '0', '1', '1']\n",
      "[81, 'L81', 27, 'M', 2, 'Master of Computer Applications', 0, 75, 34, 22, 62, '1', '0', '0', '1']\n",
      "[82, 'L82', 29, 'F', 2, 'Master of Computer Applications', 1, 56, 54, 81, 57, '1', '1', '1', '1']\n",
      "[83, 'L83', 24, 'F', 2, 'MTech Computer Science', 0, 54, 45, 54, 24, '1', '0', '1', '0']\n",
      "[84, 'L84', 26, 'F', 2, 'MSc Computer Science', 0, 55, 54, 87, 64, '1', '1', '1', '1']\n",
      "[85, 'L85', 25, 'F', 2, 'Master of Computer Applications', 0, 51, 82, 45, 54, '1', '1', '0', '1']\n",
      "[86, 'L86', 27, 'F', 2, 'MTech Computer Science', 0, 65, 36, 71, 88, '1', '0', '1', '1']\n",
      "[87, 'L87', 26, 'F', 2, 'MSc Computer Science', 2, 70, 45, 67, 58, '1', '0', '1', '1']\n",
      "[88, 'L88', 25, 'F', 2, 'MSc Computer Science', 0, 67, 70, 20, 40, '1', '1', '0', '0']\n",
      "[89, 'L89', 28, 'F', 2, 'MTech Computer Science', 2, 47, 62, 49, 28, '0', '1', '0', '0']\n",
      "[90, 'L90', 26, 'F', 2, 'Master of Computer Applications', 2, 30, 46, 81, 36, '0', '0', '1', '0']\n",
      "[91, 'L91', 27, 'F', 2, 'Master of Computer Applications', 0, 78, 34, 17, 87, '1', '0', '0', '1']\n",
      "[92, 'L92', 25, 'F', 2, 'MTech Computer Science', 0, 34, 34, 76, 74, '0', '0', '1', '1']\n",
      "[93, 'L93', 26, 'F', 2, 'MSc Computer Science', 0, 87, 44, 55, 65, '1', '0', '1', '1']\n",
      "[94, 'L94', 25, 'F', 2, 'Master of Computer Applications', 1, 84, 87, 54, 69, '1', '1', '1', '1']\n",
      "[95, 'L95', 24, 'F', 2, 'MTech Computer Science', 2, 23, 84, 24, 34, '0', '1', '0', '0']\n",
      "[96, 'L96', 26, 'F', 2, 'MSc Computer Science', 0, 65, 67, 58, 45, '1', '1', '1', '0']\n",
      "[97, 'L97', 25, 'F', 2, 'Master of Computer Applications', 2, 76, 86, 43, 29, '1', '1', '0', '0']\n",
      "[98, 'L98', 27, 'F', 2, 'MTech Computer Science', 1, 75, 34, 22, 62, '1', '0', '0', '1']\n",
      "[99, 'L99', 28, 'F', 2, 'MSc Computer Science', 2, 76, 37, 69, 49, '1', '0', '1', '0']\n",
      "[100, 'L100', 29, 'F', 2, 'MSc Computer Science', 0, 54, 57, 54, 24, '1', '1', '1', '0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[onto.L1,\n",
       " onto.L2,\n",
       " onto.L3,\n",
       " onto.L4,\n",
       " onto.L5,\n",
       " onto.L6,\n",
       " onto.L7,\n",
       " onto.L8,\n",
       " onto.L9,\n",
       " onto.L10,\n",
       " onto.L11,\n",
       " onto.L12,\n",
       " onto.L13,\n",
       " onto.L14,\n",
       " onto.L15,\n",
       " onto.L16,\n",
       " onto.L17,\n",
       " onto.L18,\n",
       " onto.L19,\n",
       " onto.L20,\n",
       " onto.L21,\n",
       " onto.L22,\n",
       " onto.L23,\n",
       " onto.L24,\n",
       " onto.L25,\n",
       " onto.L26,\n",
       " onto.L27,\n",
       " onto.L28,\n",
       " onto.L29,\n",
       " onto.L30,\n",
       " onto.L31,\n",
       " onto.L32,\n",
       " onto.L33,\n",
       " onto.L34,\n",
       " onto.L35,\n",
       " onto.L36,\n",
       " onto.L37,\n",
       " onto.L38,\n",
       " onto.L39,\n",
       " onto.L40,\n",
       " onto.L42,\n",
       " onto.L44,\n",
       " onto.L45,\n",
       " onto.L46,\n",
       " onto.L47,\n",
       " onto.L48,\n",
       " onto.L49,\n",
       " onto.L50,\n",
       " onto.L51,\n",
       " onto.L52,\n",
       " onto.L53,\n",
       " onto.L55,\n",
       " onto.L56,\n",
       " onto.L57,\n",
       " onto.L58,\n",
       " onto.L59,\n",
       " onto.L60,\n",
       " onto.L61,\n",
       " onto.L62,\n",
       " onto.L63,\n",
       " onto.L64,\n",
       " onto.L65,\n",
       " onto.L66,\n",
       " onto.L67,\n",
       " onto.L68,\n",
       " onto.L69,\n",
       " onto.L70,\n",
       " onto.L71,\n",
       " onto.L72,\n",
       " onto.L73,\n",
       " onto.L74,\n",
       " onto.L75,\n",
       " onto.L76,\n",
       " onto.L77,\n",
       " onto.L78,\n",
       " onto.L79,\n",
       " onto.L80,\n",
       " onto.L81,\n",
       " onto.L82,\n",
       " onto.L83,\n",
       " onto.L84,\n",
       " onto.L85,\n",
       " onto.L86,\n",
       " onto.L87,\n",
       " onto.L88,\n",
       " onto.L89,\n",
       " onto.L90,\n",
       " onto.L91,\n",
       " onto.L92,\n",
       " onto.L93,\n",
       " onto.L94,\n",
       " onto.L95,\n",
       " onto.L96,\n",
       " onto.L97,\n",
       " onto.L98,\n",
       " onto.L99,\n",
       " onto.L100]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv2StudOnto(learner_data)\n",
    "saveOntology()\n",
    "list(onto.individuals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Running HermiT...\n",
      "    java -Xmx2000M -cp C:\\Users\\Jithin\\Anaconda3\\lib\\site-packages\\owlready2\\hermit;C:\\Users\\Jithin\\Anaconda3\\lib\\site-packages\\owlready2\\hermit\\HermiT.jar org.semanticweb.HermiT.cli.CommandLine -c -O -D -I file:///C:/Users/Jithin/AppData/Local/Temp/tmpby1ouj1v\n"
     ]
    },
    {
     "ename": "OwlReadyInconsistentOntologyError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\owlready2\\reasoning.py\u001b[0m in \u001b[0;36msync_reasoner_hermit\u001b[1;34m(x, infer_property_values, debug, keep_tmp_file)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m       \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTDOUT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[1;32m--> 395\u001b[1;33m                **kwargs).stdout\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[1;32m--> 487\u001b[1;33m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['java', '-Xmx2000M', '-cp', 'C:\\\\Users\\\\Jithin\\\\Anaconda3\\\\lib\\\\site-packages\\\\owlready2\\\\hermit;C:\\\\Users\\\\Jithin\\\\Anaconda3\\\\lib\\\\site-packages\\\\owlready2\\\\hermit\\\\HermiT.jar', 'org.semanticweb.HermiT.cli.CommandLine', '-c', '-O', '-D', '-I', 'file:///C:/Users/Jithin/AppData/Local/Temp/tmpby1ouj1v']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOwlReadyInconsistentOntologyError\u001b[0m         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-e35386601820>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#just to show the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mrunQuery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparqlQueries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;31m#response=runQuery.search()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#df = pd.DataFrame(response,columns=['Name','Active','Sensitive'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-e35386601820>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mmy_world\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWorld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmy_world\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ontology\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ontology2.owl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#path to the owl file is given here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0msync_reasoner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_world\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#reasoner is started and synchronized here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_world\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_rdflib_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\owlready2\\reasoning.py\u001b[0m in \u001b[0;36msync_reasoner_hermit\u001b[1;34m(x, infer_property_values, debug, keep_tmp_file)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mb\"Inconsistent ontology\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mOwlReadyInconsistentOntologyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mOwlReadyJavaError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Java error message is:\\n%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOwlReadyInconsistentOntologyError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class SparqlQueries:\n",
    "    def __init__(self):\n",
    "        my_world = World()\n",
    "        my_world.get_ontology(\"ontology2.owl\").load() #path to the owl file is given here\n",
    "        sync_reasoner(my_world)  #reasoner is started and synchronized here\n",
    "        self.graph = my_world.as_rdflib_graph()\n",
    "\n",
    "    def search(self):\n",
    "    #Search query is given here\n",
    "    #Base URL of your ontology has to be given here\n",
    "        query ='PREFIX elearn: <http://elearning1.org/onto.owl#> PREFIX \txsd: <http://www.w3.org/2001/XMLSchema#>SELECT * WHERE { ?name elearn:Active_Reflective ?Active_Reflective. ?name elearn:Sensitive_Intutive ?Sensitive_Intutive. ?name elearn:Name ?Name.?name elearn:Visual_Verbal ?Visual_Verbal.?name elearn:Global_Sequential ?Global_Sequential. FILTER ((?Active_Reflective=\"1\"^^xsd:integer) && (?Sensitive_Intutive = \"1\"^^xsd:integer)) }'\n",
    "    #query is being run\n",
    "        resultsList = self.graph.query(query)\n",
    "        print(resultsList)\n",
    "\n",
    "\n",
    "        response = []\n",
    "        for item in resultsList:\n",
    "            Active = str(item['Age'].toPython())\n",
    "            Active = re.sub(r'.*#',\"\",Active)\n",
    "            Sensitive = str(item['Sensitive_Intutive'].toPython())\n",
    "            Sensitive = re.sub(r'.*#', \"\", Sensitive)\n",
    "            Name = str(item['Name'].toPython())\n",
    "            Name = re.sub(r'.*#', \"\", Name)\n",
    "            response.append([Name,age,asr])\n",
    "            return response;\n",
    "\n",
    "        print(response) #just to show the output\n",
    "runQuery = SparqlQueries()\n",
    "#response=runQuery.search()\n",
    "#df = pd.DataFrame(response,columns=['Name','Active','Sensitive'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "try:\n",
    "    imp.find_module('owlready')\n",
    "    found = True\n",
    "except ImportError:\n",
    "    found = False\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
